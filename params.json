{"name":"On working with The Virtual Brain ","tagline":"and some non virtual thoughts about Google Summer of Code 2014.","body":"<script type=\"text/javascript\" src=\"http://d3js.org/d3.v3.min.js\" charset=\"utf-8\"></script>\r\n<script type=\"text/javascript\" src=\"javascripts/jquery.js\" charset=\"utf-8\"></script>\r\n<script type=\"text/javascript\" src=\"javascripts/jqueryui.js\" charset=\"utf-8\"></script>\r\n<script type=\"text/javascript\" src=\"javascripts/timeseriesFragment.js\" charset=\"utf-8\"></script>\r\n<script type=\"text/javascript\" src=\"javascripts/rainbowvis.js\" charset=\"utf-8\"></script>\r\n\r\n### What is this about? \r\n\r\nHi all, my name is Robert Parcus and I'm a CS student\r\nfrom UNIPG (Italy). I'm moving to Hong Kong this September to further my studies\r\nand my plan for the Summer of 2014 was to participate in this year's [Google\r\nSummer Of Code](https://www.google-melange.com/gsoc/homepage/google/gsoc2014).\r\n\r\nGladly, I was accepted as a student in this amazing project and here I would\r\nlike to spend a few words about the whole experience. Going from the application\r\nphase up to the finishing days. I hope you will enjoy the journey as much as I\r\ndid.\r\n\r\n### The Application Phase\r\n\r\nAfter browsing the list of accepted organizations, I quickly decided that I\r\nwanted to apply for one of [INCF](http://incf.org)'s  13\r\n[projects](http://incf.org/gsoc).  I started to read about them and even if I\r\ndidn't know anything about The Virtual Brain before, it really got stuck in my\r\nhead (pun intended).\r\n\r\n[The Virtual Brain](http://thevirtualbrain.com/) is a set of tools for\r\nsimulating the human brain based on large scale connectivity. It can be used as\r\na Neuroscience scientific library for python or as a super cool framework,\r\ncomplete with a web based user interface full of\r\n[visualizers](http://docs.thevirtualbrain.org/basic/link_user_guide.html#time-\r\nseries-volume-visualizer).\r\n\r\nHere is a small video about The Virtual Brain.\r\n[![The Virtual Brain Video](http://img.youtube.com/vi/RZgULkLKqu8/0.jpg)](https://www.youtube.com/watch?v=RZgULkLKqu8)\r\n\r\n### My Mentors\r\n\r\nThe mentors are the links between us students and the organizations we are\r\nworking with.\r\n\r\nEven before GSoC begins, students are advised to contact their hosting\r\norganizations to discuss about their working proposals. Since I didn't knew TVB\r\nbeforehand, I wrote them as soon as I could and to my surprise they replied\r\nback! :)\r\n\r\nFrom my point of view, the people working on The Virtual Brain were like super\r\nstars and to see that we could exchange ideas, just like that, was a great thing\r\nfor me. They had an advice for every and each one of my doubts, and they helped\r\nme not only in the application phase but also during my three months of work on\r\nGSoC, when they were always ready to help me polish my code and make good\r\nsuggestions.\r\n\r\n@liadomide (Lia Domide) and @pausz (Paula Sanz-Leon) were my mentors during this\r\nGSoC and I'm really thankful for all their time, patience and expertise. It is a\r\npleasure know them.\r\n\r\nAlso I must thank @maedoc (Marmaduke Woodman) who was not officially my mentor\r\nbut gave a great hand during all the process.\r\n\r\nIf I were to say which was the hardest part of GSoC. I'd say that it was\r\ndefinitely the application part.\r\n\r\nAfter a lot of thinking and talking with my mentors, the application deadline was\r\nalmost coming and I decided to send Google my proposal.\r\n\r\n### Volumetric Time series visualizer for TVB and updating other visualization tools\r\n\r\nThis was the final title of my proposal. From the Google-melange website:\r\n\r\n>**Organization:** International Neuroinformatics Coordinating Facility\r\n\r\n>**Assigned mentors:** Lia Domide, Paula Sanz-Leon\r\n\r\n>**Short description:** The main goal of this proposal is to implement a time-\r\nseries visualizer for 4D data in TVB, which would enable users to work with\r\ntheir functional MRI data directly from the browser. Then I will work on\r\nrewriting some of the visualizers that are currently implemented using\r\nMatplotLib and MPLH5, backed with web-friendly tools.\r\n\r\nThe proposal itself was much bigger and specific than this. The whole\r\napplication phase was already a big challenge by itself. It was my first time\r\nplanning for  a project this big and I learned a lot during the process. Again,\r\na big help came from my mentors who always had good suggestions ready.\r\n\r\n### Wating for results\r\n\r\nWell, I would love to say that I simply waited and crossed my fingers, but no.\r\nI was really nervous about the outcome of the selection process and I remember that\r\nI also sent some of my stress to my mentors: \r\n*\"Is the application good enough?\", \"Should I have changed [...] to [...]?\",\r\n\"Should I have added more features to the proposal?\", etc*.\r\nAt this point, a well placed \"Don't worry\" from them was really helpful. :)\r\n\r\n### On being Accepted\r\n\r\nI just want to leave a small note about this, since the overall sensation of a\r\nsuccessful application should be obvious to everyone already:\r\n\r\nIt is hard to describe how happy I was when I read my name among the selected\r\nstudents. Google-melange sent me a few emails, the INCF started tweeting about\r\nit. I was added to the GSoC students mailing list where more than a thousand\r\nstudents from all over the world where talking about their experiences and\r\nasking for advice from other students (also, a lot of spam!). I suddenly had\r\nto (re-)read a lot of related documents, FAQs, emails. It was overwhelming!\r\n\r\nI then proceeded to tweet about it myself and share some links on G+, but at\r\nfirst I did so on a very timid fashion.\r\n\r\nI only really talked about GSoC in detail to a few close friends and colleagues.\r\nBefore everything really started, I feared that the adventure was too big for me\r\nto handle and if I were to fail, I would want people to know as little as\r\npossible about it. It turns out that this was nothing but a silly behavior.\r\n\r\nThe more they know about what you do, the more your friends can support and\r\nunderstand you, in good or bad times.\r\n\r\nThe next time that someone calls me out for a movie or similar things I won't\r\njust say that I'm busy or come up with general excuses. I will probably be\r\nspecific and just say the truth:\r\n\r\n_\"Sorry, I have to work on a neuroscience data\r\nvisualization thing and I'm really into it. Maybe next week? :)\"_\r\n\r\n### About the Implementation\r\n![The Visulizer Prototype](https://raw.githubusercontent.com/quiuquio/tvb-framework/gh-pages/images/tvbPost/first.png \"The Visulizer Prototype\")\r\n\r\nWe decided to work on an already implemented prototype. The basic features to\r\ndisplay the slices were already in place but the visualizer was missing its\r\nplayback  functionalities.\r\n\r\nAlso, since fMRI data can be huge, a buffering mechanism was necessary in order\r\nto load the required information and display it as fast as possible on the\r\nbrowser.\r\n\r\nAt first, I decided to give our visualizer a real user interface, so that I\r\ncould test it directly as a user would do, without having to rely only on the\r\nconsole. The UI would also help display some information about the data being\r\nvisualized, like selected time point and coordinates. Moreover, I tried to\r\nresize the quadrants and give each one of them a margin.\r\n\r\nAfter playing around with the quadrants settings and using jQuery UI to create\r\nthe user interface I had something very basic, like this:\r\n![First UI](https://raw.githubusercontent.com/quiuquio/tvb-framework/gh-pages/images/tvbPost/second.png \"First UI\")\r\n\r\nNow, for the hard part, it was time to focus on the buffering and the playback\r\nfeatures.\r\n\r\nMy first attempt was to load everything in memory, but soon it was clear that\r\nthis was not a realistic approach. A compressed fMRI file can easily occupy\r\nhundreds of Megabytes, hence loaded, uncompressed data could easily surpass the\r\nGigabyte mark.\r\n\r\nFor example, we had a 91x109x91 voxels test set which was 177 frames long. In\r\nthe client side the data would become a double-precision  array with\r\n159765333 elements. Such a big javascript array is just an easy way to crash\r\nyour browser.\r\n\r\nOn the other hand, a purely lazy approach was also a bad solution: To query for\r\na single frame, wait for the server to prepare it, receive the json data and\r\nparse it was either too slow or an overall waste of bandwidth, because of the\r\noverhead of requesting only one frame at a time.\r\n\r\nAlso, even if AJAX calls can be made asynchronously, the playback and UI would\r\nall freeze while waiting for the parsing operations.\r\n\r\nTo avoid blocking the main thread we used webworkes for parsing the json. An in-\r\nline wrapper was used so that we didn't need to use a separate file for the\r\nwebworker code.\r\n\r\n```javascript\r\nfunction inlineWebWorkerWrapper(workerBody){\r\n    var retBlob = URL.createObjectURL(\r\n        new Blob([\r\n            '(',\r\n                workerBody.toString(),\r\n            ')()' ],\r\n        { type: 'application/javascript' }\r\n        )\r\n    );\r\n    return retBlob;\r\n}\r\n```\r\nWhile the parsing function was similar to:\r\n```javascript\r\nvar parserBlob = inlineWebWorkerWrapper(\r\n            function(){\r\n                self.addEventListener( 'message', function (e){\r\n                    // Parse JSON, send it to main thread, close the worker\r\n                    self.postMessage(JSON.parse(e.data));\r\n                    self.close();\r\n                }, false );\r\n            }\r\n        );\r\n\r\nfunction parseAsync(data, callback){\r\n    var worker;\r\n    var json;\r\n    if( window.Worker ){\r\n        worker = new Worker( parserBlob );\r\n        worker.addEventListener( 'message', function (e){\r\n            json = e.data;\r\n            callback( json );\r\n        }, false);\r\n        worker.postMessage( data );\r\n    }\r\n    else{\r\n        json = JSON.parse( data );\r\n        callback( json );\r\n    }\r\n}\r\n```\r\n\r\nIt is important to remember that this approach **will not** speed up the parsing\r\nitself (it may even delay it). Its only benefit is that the main thread will\r\nnever freeze while waiting for the parsing to happen and during playback this\r\nis exactly what we need.\r\n\r\nWith the parsing problem solved, the next thing was buffering.\r\n\r\nThe visualizer checks the selected voxel and asynchronously queries the server\r\nfor batches of frames of the three visible planes only. If our data is composed\r\nof n sized MRI \"cubes\", this approach reduces the spatial complexity of each\r\nframe from O(n^3) to O(n^2).\r\n\r\nIf the user clicks the planes to navigate in space, we halt the buffering of\r\nfuture frames and synchronously load the complete cube data for that time point.\r\nA little delay was expected in this cases but we noticed that it consisted of a\r\nnegligible wait for average resolution data. As soon as the user stops picking,\r\nwe can resume playback again, together with the buffering of future data based\r\non the new selected voxel.\r\n\r\nCoupled with the buffering system, a safety procedure was put in place \r\nto keep the memory footprint always under a certain threshold.\r\n\r\n### Time Series Fragment Visualizer\r\n\r\nAfter the completion of the Volumetric Time Series Visualizer, we decided to\r\nfocus on Time Series visualization.  The technology of choice was\r\n[D3.js](www.d3js.org) and at the end of the project the result was similar to\r\nthis:\r\n\r\n```javascript\r\n/**\r\n * Click on the graph to interact with it. This is a dumbed down version of the\r\n * new TVB Time Series Visualizer that I hacked on this page.\r\n *\r\n * It's displaying random data.\r\n * \r\n * Click on the colored lines to sort them and move the brush in the middle to\r\n * focus on a specific area of the time series.\r\n */\r\n```\r\n\r\n<div id=\"ts-graph-parent\">\r\n    <div id=\"graph\" class=\"aGraph\"></div>\r\n</div>\r\n\r\n<script type=\"text/javascript\">\r\n    $(function(){\r\n        TSF_initVisualizer();\r\n        drawGraphs()\r\n    })\r\n</script>\r\n\r\nA better description of how this visualizer works can be seen in the TVB\r\ndocumentation and for some cool (at least for me) insider information about it,\r\nyou can take a look at this [now closed pull request on the TVB github\r\nrepository](https://github.com/the-virtual-brain/tvb-framework/pull/12). \r\n\r\n![Time Series Fragment](https://raw.githubusercontent.com/quiuquio/tvb-framework/gh-pages/images/tvbPost/third.jpg \"Time Series Fragment\")\r\n\r\nIn the last days of the project, I restyled the visualizer and cleaned the code\r\nto a point were I felt it was ready to belong to an open source project.\r\n\r\nAll the code can now be seen on [The Virtual Brain's github\r\nrepositories](https://github.com/the-virtual-brain).\r\n\r\nThe final result looks like this: \r\n\r\n![Final Result](https://raw.githubusercontent.com/quiuquio/tvb-framework/gh-pages/images/tvbPost/fourth.png \"Final Result\")\r\n\r\n\r\n#Final Thoughts\r\n\r\nAfter more than three months of work Google Summer of Code 2014 has finished.\r\nI'm glad that I was able to open this chapter in my life and I'm also glad that\r\nit added many novelties to my story. I hope that I will be able collaborate\r\nagain with the folks at The Virtual Brain and I'm also tankful to my loved ones\r\nwho gave me a lot of support during the last months (as they always did\r\nactually). Thanks!\r\n\r\nIf I must give a two words advice about GSoC to all my fellow students, it is\r\nthe following:\r\n\r\n**Do it.**\r\n\r\nReally, just do it. Don't be afraid to push your limits. A lot of great things\r\nare waiting just outside your comfort zone.\r\n\r\nThanks for reading this,\r\nRobert Parcus 2014\r\n\r\n---\r\n\r\nNow, after I'm done sounding like I'm a Nike advertiser, if you think that this\r\npage is missing some information, or you simply want to chat about anything,\r\nyou can find me at betoparcus@gmail.com\r\n\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}